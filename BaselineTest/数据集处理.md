# 数据集处理

### 备注

全部处理为：
- 节点数 100
- 时间步 几百
- 权重 [0,1]

NetworkGAN的特征不知道是啥东西，尺寸(435,2)，Mesh有445个快照，疑似每个快照一个特征
弄不懂弄不懂，不用这个模型了

### 选用的数据集、及处理情况

- Mesh
  - O
- Hmob
- T-Drive
- IoT
  - O
- sbm_50t_1000n_adj
  - O
- soc-sign-bitcoinalpha
  - O
- soc-sign-bitcoinotc
  - O

### 目标格式

- 数据集_edge.npy
  - 时间1快照：List(源节点，目标节点，边权重)
  - 时间2快照：List(源节点，目标节点，边权重)
  - ...
  - 无边权重时，边权重=1.0
  - 例如

    ```text
    list([(0, 2, 4.388438), (0, 5, 19.666185), (0, 7, 266.816686)...
    list([(0, 2, 6.030252), (0, 5, 35.406095), (0, 7, 282.108981)...
    ```

- 数据集_feat.npy（如有）
  - 矩阵（疑似onehot向量，横向量，节点特征）

### 原数据格式

#### 简明的格式

**sbm**

```
source,target,weight,time
0,2,1,0
0,3,1,0
```

没有权重，节点为整数代号，没有节点特征，时间为整数等间距时间步

**bitcoin alpha / bitcoin otc (BC-OTC, BC-Alpha)**
  
```
SOURCE, TARGET, RATING, TIME
7188,1,10,1407470400
430,1,10,1376539200
```

- 权重为 $[-10,10]$ 整数，节点为整数代号，没有节点特征，时间为整数等间距时间步（unix时间戳，整数）
- otc
  - 节点数: 5881, 时间范围: (1289241911, 1453684323), 权重范围: (-10, 10)
- sbm
  - 节点数: 1000, 时间范围: (0, 49), 权重范围: (1, 1)

#### IP网络连接

**IoT**

文件夹结构

```
IoT
|——日期.csv
|——16-09-23.csv
...
```

数据格式及示例

```
Packet ID,TIME,Size,eth.src,eth.dst,IP.src,IP.dst,IP.proto,port.src,port.dst
1,1474552802,70,18:b7:9e:02:20:44,14:cc:20:51:33:ea,192.168.1.120,46.105.38.79,6,40234,5228
2,1474552802,66,18:b7:9e:02:20:44,14:cc:20:51:33:ea,192.168.1.120,46.105.38.79,6,40234,5228
3,1474552802,66,14:cc:20:51:33:ea,30:8c:fb:2f:e4:b2,52.87.241.159,192.168.1.106,6,443,46330

```

- txt文件的unix时间都是连着的，可以一起处理
- 一个txt有近70万条连接
- IOT第一天的数据情况
  - 时间范围: (1474552802.0, 1474639199.0)
  - 节点个数: 13081
  - 总边数: 26922（这个数据有问题，应该是这些种连接）


**mesh**

文件夹结构

```
mesh
|——时间段
    |——时间戳（无扩展名文件）
    |——neighbortable-1143927049
    ...
|——1143927049-1143953729
...
```

数据格式

```
（在同一个时间戳里）
源节点1 目标节点1 权重1 目标节点2 权重2
源节点2 ...
...
```

数据示例

```
# Neighbor table generated by summarizer
# Creation date - Sat May 13 14:16:38 PDT 2006
10.1.1.2 10.1.1.106 36.28401 10.1.1.60 0.4560859 10.1.1.9 4.6353765 10.1.1.100 1.678032 10.1.1.25 316.12903 10.1.1.103 19.597902
10.2.1.2 10.2.1.60 0.18406816 10.2.1.100 1243.8635
10.1.1.60 10.1.1.2 0.4560859 10.1.1.102 8.813054 10.1.1.106 4.682107 10.1.1.7 53.454887 10.1.1.100 2.03909 10.1.1.3 1.598287 10.1.1.25 2.7416239 10.1.1.103 1.6299783 10.1.1.21 19.824602 10.1.1.9 1.7308663 10.1.1.101 5.0224986 10.1.1.105 30.888975 10.1.1.5 4.679364
```

- 一个文件约有40行（节点数）
- 有特别多时间戳的文件
- **注：不确定OpenTLP示例中mesh的属性矩阵哪来的，论文也没有提到**
- 分析结果: {'num_nodes': 38, 'weight_range': (0.02331826, 26509.547), 'time_range': (1143927049, 1144450056), 'file_count': 1725}
- 快照数：446 + 333 + 950
- 节点 ID 映射: {'10.1.1.100': 0, '10.1.1.101': 1, '10.1.1.102': 2, '10.1.1.103': 3, '10.1.1.105': 4, '10.1.1.106': 5, '10.1.1.109': 6, '10.1.1.2': 7, '10.1.1.20': 8, '10.1.1.21': 9, '10.1.1.25': 10, '10.1.1.27': 11, '10.1.1.3': 12, '10.1.1.4': 13, '10.1.1.5': 14, '10.1.1.60': 15, '10.1.1.7': 16, '10.1.1.8': 17, '10.1.1.9': 18, '10.2.1.100': 19, '10.2.1.101': 20, '10.2.1.102': 21, '10.2.1.103': 22, '10.2.1.105': 23, '10.2.1.106': 24, '10.2.1.109': 25, '10.2.1.2': 26, '10.2.1.20': 27, '10.2.1.21': 28, '10.2.1.25': 29, '10.2.1.27': 30, '10.2.1.3': 31, '10.2.1.4': 32, '10.2.1.5': 33, '10.2.1.60': 34, '10.2.1.7': 35, '10.2.1.8': 36, '10.2.1.9': 37}

**处理方法**

- 考虑将一段时间内的交互次数记为权重
- 考虑将`ip:port`相同的作为同一个节点
- 先统计ip地址并映射到整数id上

#### 物理坐标

**Hmob**

文件夹结构

```
Hmob
|——地点（一个完整的图）
    |——节点1.txt
    |——节点2.txt
    ...
|——地点
...
```

数据结构说明
```
Time (seconds)             X-coordinate from a reference (meters)   Y-coordinate from a reference (meters)

0.0000000000000000e+000	   -3.8420858381879395e+002	            -4.6667833828169620e+001	
```

数据示例
```
0.0000000000000000e+000	 -4.4946491613012944e+002	  1.0800837754700985e+003	
3.0000000000000000e+001	 -4.4478582855829580e+002	  1.1125661027171002e+003	
6.0000000000000000e+001	 -4.4376396128203868e+002	  1.1046069279548926e+003	
```

- 节点数
  - kaist：92
  - ncsu：35
  - newyork：39
  - orlando：41
  - statefair：19

节点的汇报时间相同，30s一次


**T-Drive**

文件夹结构

```
T-Drive
|——节点id.txt
|——1.txt
...
```

数据示例

```
1,2008-02-02 15:36:08,116.51172,39.92123
1,2008-02-02 15:46:08,116.51135,39.93883
1,2008-02-02 15:46:08,116.51135,39.93883
...
2,2008-02-02 13:33:52,116.36422,39.88781
2,2008-02-02 13:37:16,116.37481,39.88782
2,2008-02-02 13:38:53,116.37677,39.88791
```

数据结构

```
taxi id, date time, longitude, latitude
```

数据每10min汇报一次，但每个节点汇报的时间不同步

**处理方式**

- 权重为
  $
    \text{weight} = \begin{cases}
    \text{max\_distance} - \text{distance} &\ \text{若distance}<\text{max\_distance} \\
    0 &\ \text{其他} \\
    \end{cases} 
    \\
    \text{distance} = x_1 - y_1 + x_2 - y_2
  $
  - 需要先统计距离的分布
- 考虑使用一段时间的平均坐标计算
  - 需要确定一段时间的平均坐标不会趋于中心点
- 节点数：10357

---

编写python程序，完成以下要求：
1. 程序的功能是将原始数据格式转化为目标数据格式，为此，需要编写函数
  ```
  def convert_data(input_csv, tau, save_npy=True, r=0.9):
  ...
  return time_data
  ```
  这个函数将会调用下面所说的全部函数

  具体要求为：
  原始数据（放在一个文件夹中）的目录
  ```
  （节点序号）
  1.txt
  2.txt
  ...
  ```
  每个文件的内容例如
  ```
  0.0000000000000000e+000	 -4.4946491613012944e+002	  1.0800837754700985e+003	
  3.0000000000000000e+001	 -4.4478582855829580e+002	  1.1125661027171002e+003	
  6.0000000000000000e+001	 -4.4376396128203868e+002	  1.1046069279548926e+003	
  ```
  其中含义为：时间，x坐标，y坐标
  注意：时间戳是等间隔的，所有文件的时间戳也都能对应

  目标格式
    - 时间1快照：List(源节点，目标节点，边权重)
    - 时间2快照：List(源节点，目标节点，边权重)
    - ...

    - 例如

      ```text
      list([(0, 2, 4.388438), (0, 5, 19.666185), (0, 7, 266.816686)...
      list([(0, 2, 6.030252), (0, 5, 35.406095), (0, 7, 282.108981)...
      ```

---

2. 将原始数据定义为动态图，具体的，在每个相同时间戳下，边是每两个节点间的坐标的函数

---

3. 首先需要将节点id转化为从0开始的连续整数id，为此，需要编写函数
  ```def map_nodes_to_ids(file_path):
  ...
  return num_nodes, mapping
  ```

---

4. 然后读取全部数据，保存在尺寸为[节点数，时间长度，3（时间戳，x坐标，y坐标）]的矩阵中，为此，需要编写函数
  ```
  def get_data(file_path):
  ...
  return data
  ```
  返回的矩阵是每个文件（读取成2维矩阵）的堆叠

---

5. 然后需要生成节点的边和对应的边权重，为此，需要编写函数
  ```
  def get_weight(data, r=0.9):
  ...
  return max_distance
  ```

  具体要求为：
      1. 定义两个节点的距离\text{distance} = x_1 - y_1 + x_2 - y_2
      2. 统计距离的分布，计算max_distance为使[0,max_distance]包含r=0.9部分的值
      3. 返回max_distance作为稍后使用的关键参数

---

6. 在函数convert_data中，我们调用上述的函数，依次完成功能“转换节点id - 读取数据 - 生成参数max_distance”；然后对`data`进行处理：

     1. 遍历全部`data`，对每两个节点（`data`堆叠的每两层）计算权重weight
       $$
           \text{weight} = \begin{cases} 
           1 - \text{distance} / \text{max\_distance}  &\ \text{若distance}<\text{max\_distance} \\
           0 &\ \text{其他} \\
           \end{cases} 
       $$
     2. 如果weight>0，则将其记录到数组time_data_raw中，格式为[时间戳，源节点，目标节点，权重]，否则不记录

---

7. 然后需要对时间降采样，为此，需要在函数convert_data中，对time_data_raw做如下处理：
    1. 对于时间戳在范围[n*tau,(n+1)*tau]内的，源节点和目标节点的组合相同的边，将他们的权重求和，作为新的权重，记录到数组time_data中的第n-1行，格式为[源节点，目标节点，权重]
    2. 例如，当tau=2时
      ```
      1 0 1 1
      1.5 0 1 2
      1.7 0 1 3
      1 0 2 4
      1.5 0 2 5
      1.7 0 2 6
      ...
      ```
      将被记录为（记录在最开始的那行）
      ```
      [0,1,6],[0,2,15],...
      ```

---

8. 将处理好的数组time_data保存，文件名为`output_file = f"{dataset_name}_len{len(time_data)}_node{num_nodes}_wei*{max_distance}.npy"`
其中dataset_name是输入文件夹的名字
然后将数组time_data返回
至此，全部功能完成